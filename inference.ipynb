{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b849de-294f-45d6-8dd5-0e91a39e0c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skt_lr_2e_5_epochs_5_length_512  skt_lr_5e_5_epochs_4_length_512  test\ttest2\n"
     ]
    }
   ],
   "source": [
    "!ls model_save/skt/ko-gpt-trinity-1.2B-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41299af5-904a-4848-8214-443a087f037a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "!python3 prediction.py --model_fn 'model_save' \\\n",
    "--pretrained_model_name skt/ko-gpt-trinity-1.2B-v0.5 \\\n",
    "--top_k 20 \\\n",
    "--top_p .85 \\\n",
    "--num_return_sequence 1 \\\n",
    "--temperature 2 \\\n",
    "--repetition_penalty 1.5 \\\n",
    "--prompt '서울역에 도착하자마자 발견한 것은 시위하는 사람들이었다.' \\\n",
    "--fine_tune \\\n",
    "--name skt_lr_2e_5_epochs_5_length_512 \\\n",
    "--max_length 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "872244c0-43d3-4874-8f08-e24da41430fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 아이들은 자란다. 한 사람만 빼고. 그 아이만이 내가 된다. 나는 그렇게 어른이 되어 간다. 그리고 어느 시점이 되면 아이는 나로 인해 또 다른 나를 만나게 될 것이고 그때 다시 한번 마주할 나의 얼굴과 새로운 이름, 더 많이 만나게 되는 많은 만남들. 내 아이의 얼굴이 조금씩 변화한다. 그런 날이 오기를.. 지금보다 조금 덜 외로워지길 기도해본다. 우리 조금만 힘내요! 우리가 다 같이 함께 잘 해냈어요! 오늘도 화이의 웃는 얼굴을 볼 수 있기를 진심으로 바랍니다. 2021. 2. 16 오후 6시 53분, 씀 이 글은 저의 육아일기장에 썼던 글을 재편집 하여 게시하였습니다~ 부족한 글 읽느라 고생 많았어요, 앞으로도 열심히 올릴테니, 관심갖아주셔서 감사드립니다~~>-< (아래의 손가락 추천 꾸욱 눌러주세요.) [11년 6월 14일 밤 7시 59분] 1. 오늘의 날씨: 비가 부슬부슬 내렸다 곧 맑음이 올 듯 하지만 아직 흐리다 그럼에도 하늘이 예쁘다고 말해주었다 - 아침을\n"
     ]
    }
   ],
   "source": [
    "!python3 prediction.py --model_fn 'model_save' \\\n",
    "--pretrained_model_name skt/ko-gpt-trinity-1.2B-v0.5 \\\n",
    "--top_k 20 \\\n",
    "--top_p .85 \\\n",
    "--num_return_sequence 1 \\\n",
    "--temperature 2 \\\n",
    "--repetition_penalty 1.5 \\\n",
    "--prompt '모든 아이들은 자란다. 한 사람만 빼고.' \\\n",
    "--fine_tune \\\n",
    "--name test2 \\\n",
    "--max_length 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3543d455-0709-45d9-801f-b1adcb35a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/bkt/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"prediction.py\", line 85, in <module>\n",
      "    main(config)\n",
      "  File \"prediction.py\", line 50, in main\n",
      "    model_config = torch.load(os.path.join(path, 'best_.pt'), map_location='cuda:0')['config']\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 789, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 1131, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/pickle.py\", line 1212, in load\n",
      "    dispatch[key[0]](self)\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/pickle.py\", line 1253, in load_binpersid\n",
      "    self.append(self.persistent_load(pid))\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 1101, in persistent_load\n",
      "    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 1083, in load_tensor\n",
      "    wrap_storage=restore_location(storage, location),\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 1052, in restore_location\n",
      "    return default_restore_location(storage, map_location)\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 215, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/serialization.py\", line 187, in _cuda_deserialize\n",
      "    return obj.cuda(device)\n",
      "  File \"/root/anaconda3/envs/bkt/lib/python3.8/site-packages/torch/_utils.py\", line 80, in _cuda\n",
      "    untyped_storage = torch.UntypedStorage(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 14.61 GiB total capacity; 3.97 GiB already allocated; 33.62 MiB free; 4.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python3 prediction.py --model_fn 'model_save' \\\n",
    "--pretrained_model_name skt/ko-gpt-trinity-1.2B-v0.5 \\\n",
    "--top_k 20 \\\n",
    "--top_p .85 \\\n",
    "--num_return_sequence 1 \\\n",
    "--additional_training \\\n",
    "--temperature 1.3 \\\n",
    "--repetition_penalty 1.5 \\\n",
    "--prompt '<나는 무엇을 위해 살아가고 있는가? 나는 누구인가. 지금, 이 순간 나답게 살고 있는가. 스스로 질문해보자. 나의 욕구와 욕망은 무엇인가? 그리고 그 안에서 행복을 찾으려고 노력하는가? 그렇다면 나도 그들과 같은 삶을 살아갈 수 있지 않을까?> <지금 당장 시작하라! 무엇이든 할 준비가 되었다면, 이제 행동으로 옮겨라. 그렇게 하면 모든 일이 술술 풀릴 것이다. - 헨리 포드-> <나다운 삶이란 나에게 주어진 일을 제대로 하는 것이 아니라 내 안에 내재된 욕구를 발견하고 그것을 실현하는 것을 의미한다. 앎과 실천의 균형을 이루는 삶이야말로 진정한 자기다움이다. 쉼 없이 변화하고 성장하면서 자신의 욕망을 발견하고, 이를 통해 행복한 삶에 이르는 과정을 반복적으로 수행하는 과정에서 우리는 자신이 원하는 삶의 모습을 만들어 갈 수도 있다. 얄궂게도 우리 대부분은 이런 과정 자체를 두려워한다. 섣불리 시도했다가는 아무것도 하지 못하고 시간만 낭비할 것이라는 두려움 때문이다. 하지만 이렇게 용기 내어 도전해보면 어떨까.숱한 실패와 좌절을 경험하더라도 다시 일어나서 목표를 향해 나아갈 수 있을지도 모른다. 엊그제까지만 해도 보이지 않던 것들이 보이기 시작한다.' \\\n",
    "--fine_tune \\\n",
    "--name skt_lr_2e_5_epochs_5_length_512 \\\n",
    "--max_length 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e516e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 17 23:03:49 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   47C    P0    26W /  70W |  10133MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d325b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bkt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "39ec93b9529723a4f0d6067f60399a1c0688f3bd99d3e8bae4318326ace18adc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
